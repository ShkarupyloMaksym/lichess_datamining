{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShkarupyloMaksym/lichess_datamining/blob/main/db_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "4EnTmq4dkNtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install zstandard\n",
        "!pip install chess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8gXuMsBoEY5",
        "outputId": "2b09b8f9-91f5-4871-d740-adee56d64f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting zstandard\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zstandard\n",
            "Successfully installed zstandard-0.22.0\n",
            "Collecting chess\n",
            "  Downloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: chess\n",
            "Successfully installed chess-1.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import zstandard as zstd\n",
        "import chess.pgn\n",
        "import os\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "ZTvD-qepkNfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constants"
      ],
      "metadata": {
        "id": "aZQEqz92k6iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_name = '2013 - July'\n",
        "data_name = '2017 - May'\n"
      ],
      "metadata": {
        "id": "ypUWzcggk8h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_of_evaled_dataset = 1000"
      ],
      "metadata": {
        "id": "zeqZ1rL4W-nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_of_cutted_dataset = 1008"
      ],
      "metadata": {
        "id": "wWOEbRVFLSFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "ywf4rXPoklZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_size = 1024\n",
        "def month_name_to_number(month_name):\n",
        "    date_obj = datetime.datetime.strptime(month_name, \"%B\")\n",
        "    month_number = date_obj.month\n",
        "    return str(month_number).zfill(2)\n",
        "\n",
        "\n",
        "def download_file_from_link(url, save_path):\n",
        "    print('Start download')\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "        progress_bar = tqdm(total=total_size_in_bytes, unit='B', unit_scale=True)\n",
        "        with open(save_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=chunk_size):\n",
        "                f.write(chunk)\n",
        "                progress_bar.update(len(chunk))\n",
        "        progress_bar.close()\n",
        "        print(\"File downloaded successfully!\")\n",
        "\n",
        "\n",
        "def decompress_file(name_start, name_end):\n",
        "    print('Start decompressing')\n",
        "    with open(name_start, 'rb') as compressed:\n",
        "        dctx = zstd.ZstdDecompressor()\n",
        "        with open(name_end, 'wb') as decompressed, dctx.stream_reader(compressed) as reader:\n",
        "            with tqdm(unit='B', unit_scale=True, desc=\"Decompressing\") as pbar:\n",
        "                while True:\n",
        "                    chunk = reader.read(chunk_size)\n",
        "                    if not chunk:\n",
        "                        break\n",
        "                    decompressed.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "    print('File decompressed')\n",
        "\n",
        "\n",
        "def create_link_from_name(data_name):\n",
        "  year, month = data_name.split(' - ')\n",
        "  month = month_name_to_number(month)\n",
        "  link_to_file = f'https://database.lichess.org/standard/lichess_db_standard_rated_{year}-{month}.pgn.zst'\n",
        "  return link_to_file\n",
        "\n",
        "def download_and_decompress(link, final_name):\n",
        "  name = link.split('/')[-1]\n",
        "  download_file_from_link(link, name)\n",
        "  decompress_file(name, final_name)"
      ],
      "metadata": {
        "id": "myMsG0YilHGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download"
      ],
      "metadata": {
        "id": "qXN_YnKYGNx_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-t8QJU6j9et",
        "outputId": "2702c117-556b-4957-f37b-b61f6692422a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start download\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.59G/3.59G [01:53<00:00, 31.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded successfully!\n",
            "Start decompressing\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Decompressing: 25.0GB [04:28, 92.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File decompressed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "url = create_link_from_name(data_name)\n",
        "final_name = url.split('/')[-1][:-4]\n",
        "download_and_decompress(url, final_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create small"
      ],
      "metadata": {
        "id": "hBFeEt2fGNCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output_file_name = f'first_{size_of_cutted_dataset}_lines_{final_name}'\n",
        "\n",
        "# with open(final_name, 'r') as input_file, open(output_file_name, 'w') as output_file:\n",
        "\n",
        "#     for _ in range(size_of_cutted_dataset):\n",
        "#         line = input_file.readline()\n",
        "#         if not line:\n",
        "#             break\n",
        "\n",
        "#         output_file.write(line)"
      ],
      "metadata": {
        "id": "MtsF2OvvpIOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count number of games in big pgn file"
      ],
      "metadata": {
        "id": "zNOSDgaFGUMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_games_in_pgn_file(input_filename):\n",
        "    game_count = 0\n",
        "\n",
        "    with open(input_filename, 'r', encoding='utf-8') as pgn:\n",
        "        for line in pgn:\n",
        "            if line.startswith('[Event '):\n",
        "                game_count += 1\n",
        "\n",
        "    print(f\"Total number of games in {input_filename}: {game_count}\")\n",
        "\n",
        "\n",
        "count_games_in_pgn_file('lichess_db_standard_rated_2017-05.pgn')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdAKAGvUd-Gb",
        "outputId": "99e8b9cd-45f9-49b2-9e8a-6a5250f4fc76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of games in lichess_db_standard_rated_2017-05.pgn: 11693919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split big pgn in n small"
      ],
      "metadata": {
        "id": "G3KkO8i4GkMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_pgn_by_event_with_logging(input_filename, output_filename_pattern, num_of_games_per_file):\n",
        "    game_count = 0\n",
        "    file_index = 1\n",
        "    current_file_game_count = 1\n",
        "    output_file = open(output_filename_pattern.format(file_index), 'w', encoding='utf-8')\n",
        "\n",
        "    with open(input_filename, 'r', encoding='utf-8') as pgn:\n",
        "        for line in pgn:\n",
        "            # Check if the line is the start of a new game\n",
        "            if line.startswith('[Event ') and current_file_game_count > 0:\n",
        "                game_count += 1\n",
        "                current_file_game_count += 1\n",
        "\n",
        "                # Log every 10k games processed\n",
        "                if game_count % 100000 == 0:\n",
        "                    print(f\"Processed {game_count} games so far...\")\n",
        "\n",
        "                # If the current output file has reached the limit, start a new file\n",
        "                if current_file_game_count > num_of_games_per_file:\n",
        "                    output_file.close()\n",
        "                    file_index += 1\n",
        "                    current_file_game_count = 1  # Reset game count for the new file\n",
        "                    output_file = open(output_filename_pattern.format(file_index), 'w', encoding='utf-8')\n",
        "\n",
        "            # Write the current line to the current output file\n",
        "            output_file.write(line)\n",
        "\n",
        "    # Close the last output file\n",
        "    output_file.close()\n",
        "\n",
        "    print(f\"Total games processed: {game_count}\")\n",
        "    print(f\"Total files created: {file_index}\")\n",
        "\n",
        "# Example usage\n",
        "input_filename = 'lichess_db_standard_rated_2017-05.pgn'\n",
        "output_filename_pattern = 'output_pgn_part_{}.pgn'  # {} will be replaced by the part number\n",
        "num_of_games_per_file = 1_000_000  # Example: 1 million games per file\n",
        "\n",
        "split_pgn_by_event_with_logging(input_filename, output_filename_pattern, num_of_games_per_file)"
      ],
      "metadata": {
        "id": "lAjtKeS473Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create pgn with only evaluated games"
      ],
      "metadata": {
        "id": "fIi9v1H2G5--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "def game_contains_eval(game):\n",
        "    \"\"\"Check if a game contains evaluation comments.\"\"\"\n",
        "    node = game\n",
        "    while not node.is_end():\n",
        "        next_node = node.variation(0)\n",
        "        if \"[%eval\" in next_node.comment:\n",
        "            return True\n",
        "        node = next_node\n",
        "    return False\n",
        "\n",
        "def random_chance_with_seed(probability):\n",
        "    \"\"\"Return True with the given probability using a fixed seed.\"\"\"\n",
        "    return random.random() < probability\n",
        "\n",
        "def filter_games_with_eval(input_filename, output_filename):\n",
        "    file_size = os.path.getsize(input_filename)\n",
        "    progress_bar = tqdm(total=file_size, unit='B', unit_scale=True, desc=\"Processing\")\n",
        "    current_position = 0\n",
        "\n",
        "    with open(input_filename, \"r\", encoding=\"utf-8\") as pgn_in:\n",
        "        # Initialize tqdm with the file size as total progress measurement\n",
        "            with open(output_filename, \"w\", encoding=\"utf-8\") as pgn_out:\n",
        "                while True:\n",
        "                    current_pos = pgn_in.tell()\n",
        "                    game = chess.pgn.read_game(pgn_in)\n",
        "                    if game is None:\n",
        "                        break\n",
        "                    # Update tqdm based on the bytes read\n",
        "                    progress_bar.update(pgn_in.tell() - current_pos)\n",
        "\n",
        "                    if game_contains_eval(game):\n",
        "                        pgn_out.write(str(game) + \"\\n\\n\")\n",
        "\n",
        "def filter_games_with_eval(input_filename, output_filename, num_of_games=None, logging_num=100, probability_of_watch_game=0.08, start_index=1, end_index=None):\n",
        "    \"\"\"Filter games that contain evaluation comments and save them to a new file.\"\"\"\n",
        "\n",
        "    num_of_written_games = 0\n",
        "    total_analyzed_games = 0\n",
        "    total_games = 0\n",
        "    now = time.time()\n",
        "\n",
        "    with open(input_filename, \"r\", encoding=\"utf-8\") as pgn_in:\n",
        "\n",
        "        while True:\n",
        "            start_position = pgn_in.tell()  # Get current position in file\n",
        "            game = chess.pgn.read_game(pgn_in)\n",
        "            if game is None:\n",
        "                break  # End of file\n",
        "            total_games += 1\n",
        "\n",
        "            # Skip games until reaching the start_index\n",
        "            if total_games < start_index:\n",
        "                continue\n",
        "\n",
        "            # Stop processing if end_index is reached\n",
        "            if end_index and total_games > end_index:\n",
        "                break\n",
        "\n",
        "            if random_chance_with_seed(probability_of_watch_game):\n",
        "              total_analyzed_games += 1\n",
        "\n",
        "              if game_contains_eval(game):\n",
        "                  # Open output file in append mode to prevent overwriting content on each write\n",
        "                  with open(output_filename, \"a\", encoding=\"utf-8\") as pgn_out:\n",
        "                      print(game, file=pgn_out, end=\"\\n\\n\")\n",
        "                      num_of_written_games += 1\n",
        "                      if num_of_written_games % logging_num == 0 and num_of_written_games != 0:\n",
        "                            now_new = time.time()\n",
        "                            taken_time = round(now_new - now)\n",
        "                            taken_time_min, taken_time_sec = taken_time // 60, taken_time % 60\n",
        "                            taken_time_sec = str(taken_time_sec).zfill(2)\n",
        "                            print(f'Has written {num_of_written_games} evaluated games, analized {total_analyzed_games}, total games = {total_games}, taken time = {taken_time_min}:{taken_time_sec}')\n",
        "                            now = now_new\n",
        "                      if num_of_games is not None and num_of_written_games >= num_of_games:\n",
        "                        break\n"
      ],
      "metadata": {
        "id": "AiN6b6KjMVV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partitional_pgn_file_name = 'output_pgn_part_2.pgn'\n",
        "\n",
        "evaled_games_filename = f'evaled_{partitional_pgn_file_name}'\n",
        "filter_games_with_eval(partitional_pgn_file_name, evaled_games_filename)"
      ],
      "metadata": {
        "id": "G4-UuNnVTLns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Export to csv"
      ],
      "metadata": {
        "id": "v2mKj2RLB__M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import chess.pgn\n",
        "import pandas as pd\n",
        "\n",
        "def parse_pgn(input_filename, output_filename):\n",
        "    pgn = open(input_filename)\n",
        "    game_id = 1\n",
        "    metadata_list = []\n",
        "\n",
        "    while True:\n",
        "        game = chess.pgn.read_game(pgn)\n",
        "        if game is None:\n",
        "            break\n",
        "\n",
        "        num_moves = 0\n",
        "        moves_with_comments = []\n",
        "        node = game\n",
        "\n",
        "        while not node.is_end():\n",
        "            next_node = node.variation(0)\n",
        "            move_san = node.board().san(next_node.move)\n",
        "            comment = next_node.comment if next_node.comment else \"\"\n",
        "            nags_str = ''.join([nag_to_symbol(nag) for nag in next_node.nags])\n",
        "            move_and_comment = f\"{move_san}{nags_str} {{{comment}}}\" if comment else move_san\n",
        "            moves_with_comments.append(move_and_comment)\n",
        "            node = next_node\n",
        "            num_moves += 1\n",
        "\n",
        "\n",
        "        moves_str = ' '.join(moves_with_comments)\n",
        "\n",
        "        metadata = {\n",
        "            'GameID': game_id,\n",
        "            'Event': game.headers.get('Event', ''),\n",
        "            'Site': game.headers.get('Site', ''),\n",
        "            'Date': game.headers.get('UTCDate', ''),\n",
        "            'Time': game.headers.get('UTCTime', ''),\n",
        "            'White': game.headers.get('White', ''),\n",
        "            'Black': game.headers.get('Black', ''),\n",
        "            'Result': game.headers.get('Result', ''),\n",
        "            'WhiteElo': game.headers.get('WhiteElo', ''),\n",
        "            'BlackElo': game.headers.get('BlackElo', ''),\n",
        "            'WhiteRatingDiff': game.headers.get('WhiteRatingDiff', ''),\n",
        "            'BlackRatingDiff': game.headers.get('BlackRatingDiff', ''),\n",
        "            'ECO': game.headers.get('ECO', ''),\n",
        "            'Opening': game.headers.get('Opening', ''),\n",
        "            'TimeControl': game.headers.get('TimeControl', ''),\n",
        "            'TotalMoves': num_moves,\n",
        "            'Moves': moves_str\n",
        "        }\n",
        "        metadata_list.append(metadata)\n",
        "\n",
        "        game_id += 1\n",
        "        if game_id % 1000 == 0:\n",
        "          print(f'completed {game_id} in {input_filename}')\n",
        "\n",
        "\n",
        "    chess_games = pd.DataFrame(metadata_list)\n",
        "    chess_games.to_csv(output_filename, index=False)\n",
        "    return chess_games"
      ],
      "metadata": {
        "id": "T_eUP7I4TerO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of database parts\n",
        "for i in range(1, 13):\n",
        "  chess_games = parse_pgn(f'evaled_output_pgn_part_{i}.pgn', f'games_metadata_{i}.csv')\n",
        "  print(f'{i} file was completed')\n",
        "\n"
      ],
      "metadata": {
        "id": "b3K2hIK0Gtus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use API to get players info"
      ],
      "metadata": {
        "id": "mMQOl63pGjUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_profile(username, fields):\n",
        "    profile = {}\n",
        "    url = f'https://lichess.org/api/user/{username}'\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        account_info = response.json()\n",
        "        print(url)\n",
        "        for field in fields:\n",
        "            try:\n",
        "                keys = field.split('/')\n",
        "                value = account_info\n",
        "                for key in keys:\n",
        "                    if key in value:\n",
        "                        value = value.get(key, {})\n",
        "                    else:\n",
        "                        value = None\n",
        "                        break\n",
        "                profile[field] = value\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {field} for {username}: {e}\")\n",
        "                profile[field] = None\n",
        "    else:\n",
        "      print(response.text)\n",
        "    return profile"
      ],
      "metadata": {
        "id": "oIbfWC2aGowj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_profiles(df, fields, name_for_saving):\n",
        "  now = time.time()\n",
        "  columns_names = ['White', 'Black']\n",
        "  for column in columns_names:\n",
        "      for field in fields:\n",
        "          df[f\"{column}_{field.replace('/', '_')}\"] = None\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "      if index % 10 == 0 and index != 0:\n",
        "        now_new = time.time()\n",
        "        taken_time = round(now_new - now)\n",
        "        taken_time_min, taken_time_sec = taken_time // 60, taken_time % 60\n",
        "        taken_time_sec = str(taken_time_sec).zfill(2)\n",
        "        print(f'{index} was completed, taken time = {taken_time_min}:{taken_time_sec}')\n",
        "        df.to_csv(name_for_saving, index=False)\n",
        "        return None\n",
        "      for column in columns_names:\n",
        "        username = row[column]\n",
        "        profile = get_profile(username, fields)\n",
        "        print(profile)\n",
        "        for field, value in profile.items():\n",
        "            df.at[index, f\"{column}_{field.replace('/', '_')}\"] = value"
      ],
      "metadata": {
        "id": "OK2dWAdaGrKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = 'YOUR_LICHESS_TOKEN'\n",
        "\n",
        "headers = {\n",
        "    'Authorization': token\n",
        "}\n",
        "\n",
        "fields=[\"profile/flag\", \"createdAt\", \"playTime/total\", \"count/all\", \"tosViolation\", \"title\"]\n",
        "\n",
        "# number of metadata csv, you wanted to update\n",
        "i=9\n",
        "games_metadata = pd.read_csv(f'games_metadata_{i}.csv')\n",
        "update_profiles(games_metadata, fields, f'games_metadata_profile_{i}.csv')\n",
        "games_metadata.to_csv(f'games_metadata_profile_{i}.csv', index=False)\n",
        "print(f\"{i} file was updated\")"
      ],
      "metadata": {
        "id": "Cd5fYtcoHfnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clear files"
      ],
      "metadata": {
        "id": "A70ap37FHXUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def delete_files_with_prefix(directory, prefix):\n",
        "    \"\"\"\n",
        "    Delete files in the specified directory that start with the given prefix.\n",
        "\n",
        "    :param directory: Path to the directory containing the files.\n",
        "    :param prefix: The prefix to match for file deletion.\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.startswith(prefix):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            try:\n",
        "                os.remove(file_path)\n",
        "                print(f\"Deleted: {file_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error deleting {file_path}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "directory = '/content'\n",
        "prefix = 'output_pgn_part_'\n",
        "delete_files_with_prefix(directory, prefix)"
      ],
      "metadata": {
        "id": "o9c-gx3rjZI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Specify the file path in Colab you want to download\n",
        "file_path = '/content/output_pgn_part_1.pgn'\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download(file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SFDHritNEX5-",
        "outputId": "d8e9683c-4983-4b89-8c60-a08524b98f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d0c75c9f-5bd9-45d2-90fe-595c831ed513\", \"output_pgn_part_1.pgn\", 2135708329)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U3QDHCBWF6z-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}